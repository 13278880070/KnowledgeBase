## TransferQueue

```java
public interface TransferQueue<E> extends BlockingQueue<E> 
```

### java doc

一个BlockingQueue，生产者可以等待消费者接收元素。 TransferQueue可能在例如消息传递应用程序中很有用，其中生产者有时（使用`transfer（E）`）方法等待消费者调用take或poll接收元素，而在其他时候将元素排队（通过方法put）而不等待接收。 还可以使用tryTransfer的非阻塞和超时版本。 也可以通过hasWaitingConsumer（）查询TransferQueue，是否有任何线程等待项目，这与窥视操作相反。
与其他阻塞队列一样，TransferQueue可能是容量限制的。 如果是，则尝试的传输操作可以最初阻塞等待可用空间，和/或随后阻塞等待消费者接收。 请注意，在容量为零的队列中，例如SynchronousQueue，put和transfer实际上是同义词。

```java

boolean tryTransfer(E e, long timeout, TimeUnit unit)
    throws InterruptedException;
```

## LinkedTransferQueue

```java
public class LinkedTransferQueue<E> extends AbstractQueue<E>
    implements TransferQueue<E>, java.io.Serializable 
```



### java doc

基于链接节点的无界TransferQueue。该队列针对任何给定的生产者对元素FIFO（先入先出）进行排序。队列的头部是队列中某个生产者最长时间的元素。队列的尾部是队列中的元素，对于某些生产者来说是最短的时间。
请注意，与大多数集合不同，size方法不是恒定时间操作。由于这些队列的异步性质，确定当前元素数量需要遍历元素，因此如果在遍历期间修改此集合，则可能会报告不准确的结果。

添加，删除或检查多个元素的批量操作，例如`AbstractQueue.addAll（java.util.Collection <？extends E>）`，`removeIf（java.util.function.Predicate <？super E>）`或`forEach（java。 util.function.Consumer <？super E>）`，不保证以原子方式执行。例如，与addAll操作并发的forEach遍历可能只会观察到一些添加的元素。

该类及其迭代器实现了Collection和Iterator接口的所有可选方法。

内存一致性效果：与其他并发集合一样，在将对象放入LinkedTransferQueue之前，线程中的操作发生在从另一个线程中的LinkedTransferQueue访问或删除该元素之后的操作之前。

Slack双队列概述

双队列， 是（链接）队列，其中节点可以表示数据或请求。 当一个线程试图将一个数据节点入队但遇到一个请求节点时，它会“匹配”并删除它; 反之亦然，用于排队请求。 阻塞双队列安排排队不匹配请求的线程，直到其他线程提供匹配。 双同步队列还安排排队不匹配数据的线程也会阻塞。 双重传输队列支持所有这些模式，如调用者所指示的。

可以使用Michael＆Scott（M＆S）无锁队列算法的变体来实现FIFO双队列。它保持两个指针字段“head”，指向（匹配的）节点，该节点又指向第一个实际的（不匹配的） ）队列节点（如果为空则为null）; 和“tail”指向队列中的最后一个节点（如果为空则再次为null）。 例如，这是一个包含四个数据元素的队列：

```java
*  head                tail
*    |                   |
*    v                   v
*    M -> U -> U -> U -> U
```

已知M＆S队列算法在维护（通过CAS）这些头尾指针时容易出现可扩展性和开销限制。 这导致了减少争用变量的发展，例如消除数组和乐观后向指针。然而，当需要双重性时，双队列的性质使得更简单的策略能够改进M＆S风格的实现。

在双队列中，每个节点必须以原子方式保持其匹配状态。 虽然还有其他可能的变体，但我们在此实现这一点：对于数据模式节点，匹配需要在匹配时将非空数据值中的“item”字段CASing为null，反之请求节点，CASing来自 null到数据值。 （请注意，此类型队列的线性化属性易于验证 - 元素通过链接可用，并且通过匹配不可用。）与普通M＆S队列相比，双队列的此属性需要每个enq /另外一个成功的原子操作 deq对。 但它也可以实现队列维护机制的低成本变体。 （这种想法的变体甚至适用于支持删除内部元素的非双重队列，例如j.u.c.ConcurrentLinkedQueue。）

匹配节点后，其匹配状态永远不会再次更改。 因此，我们可以安排它们的链表包含零个或多个匹配节点的前缀，后跟零个或多个不匹配节点的后缀。 （注意，我们允许前缀和后缀都为零长度，这反过来意味着我们不使用虚拟头。）如果我们不关心时间或空间效率，我们可以正确执行入队和出队操作 遍历从指针到初始节点; 在匹配时对第一个不匹配节点的项进行CASing，并对追加到尾随节点的下一个字段进行CASing。 虽然这本身就是一个糟糕的想法，但它确实具有不需要在头/尾场上进行任何原子更新的好处。

我们在这里介绍一种方法，它位于从不与总是更新队列（头部和尾部）指针的极端之间。 这提供了在有时需要额外遍历步骤来定位第一个和/或最后一个不匹配节点之间的权衡，而不是减少的开销和对队列指针的更少更新的争用。 例如，队列的可能快照是：

```java
*  head           tail
*    |              |
*    v              v
*    M -> M -> U -> U -> U -> U
```

这种“松弛”的最佳值（“头部”和第一个不匹配节点的值之间的目标最大距离，以及“尾部”的类似）是一个经验问题。 我们发现使用1-3范围内的非常小的常数在一系列平台上工作得最好。 较大的值会导致缓存未命中的成本增加以及长遍历链的风险，而较小的值会增加CAS争用和开销。

具有松弛的双队列与普通的M＆S双队列不同，因为在匹配，附加或甚至遍历节点时，有时仅更新头部或尾部指针; 为了保持目标松弛。 “有时”的想法可以通过几种方式实现。 最简单的方法是在每个遍历步骤中使用递增计数器，并在计数超过阈值时尝试（通过CAS）更新关联的队列指针。 另一个需要更多开销的是使用随机数生成器以每个遍历步骤的给定概率进行更新。

在这些行的任何策略中，因为CAS更新字段可能失败，实际的松弛可能超过目标松弛。 但是，可以随时重试它们以维持目标。 即使使用非常小的松弛值，这种方法也适用于双队列，因为它允许所有操作直到匹配或附加项目（因此可能允许另一个线程进展）为只读，因此不会进一步引入争。 如下所述，我们通过仅在这些点之后执行松弛维护重试来实现此目的。

作为这种技术的伴随，可以进一步减少遍历开销而不增加头指针更新的争用：线程有时可以将当前“头”节点的“下一个”链路路径缩短为更接近当前已知的第一个不匹配节点，并且同样的尾巴。同样，这可以通过使用阈值或随机化来触发。
​     
必须进一步扩展这些想法，以避免由旧的遗忘头节点开始的节点的顺序“下一个”链接造成无限量的回收垃圾：正如Boehm首先详细描述的那样，如果GC延迟注意任何任意旧节点已成为垃圾，所有较新的死节点也将无法恢复。 （类似的问题出现在非GC环境中。）为了在我们的实现中处理这个问题，在CASing推进头指针时，我们将前一个头的“next”链接设置为仅指向它自己;从而限制了死节点链的长度。 （我们也会采取类似的措施来消除其他节点字段中可能存在的垃圾保留值。）但是，这样做会增加遍历的一些复杂性：如果任何“下一个”指针链接到自身，则表明当前线程落后了头部更新，因此遍历必须从“头部”继续。尝试从“尾部”开始寻找当前尾部的遍历也可能遇到自我链接，在这种情况下，它们也继续在“头部”。

在基于松弛的方案中，甚至不使用CAS进行更新（类似于Ladan-Mozes＆Shavit）是诱人的。 但是，在上述链接遗忘机制下，对于头更新无法做到这一点，因为更新可能会留在分离的节点上。 虽然直接写入可能用于尾部更新，但是它们增加了长时间撤回的风险，因此增加了长垃圾链，考虑到执行CAS与写入的成本差异较小时，这可能比成本高得多。 在每次操作时触发（特别是考虑到写入和CAS同样需要额外的GC簿记（“写入障碍”），有时因为争用而比写入本身更昂贵）。

```
Overview of implementation
```

我们使用基于阈值的方法进行更新，松弛阈值为2  - 也就是说，当当前指针看起来距离第一个/最后一个节点两步或更远时，我们更新头/尾。松弛值是硬连线的：通过检查遍历指针的相等性自然地实现大于1的路径，除非列表只有一个元素，在这种情况下我们将松弛阈值保持为1。避免在方法调用中跟踪显式计数会略微简化已经混乱的实现。如果有一个质量低劣的每线程可用的随机化可能会更好，但即使ThreadLocalRandom对于这些目的来说也太重了。
 利用这样小的松弛阈值，除了取消/移除（见下文）之外，不值得用路径短路（即，未拼接的内部节点）来增加这一点。
 所有入队/出队操作都由单个方法“xfer”处理，其中参数指示是否充当某种形式的offer，put，poll，take或transfer（每个可能都有超时）。使用单一方法的相对复杂性超过了为每种情况使用单独方法的代码批量和维护问题。

操作最多包括两个阶段。 第一个是在方法xfer中实现的，第二个是在方法awaitMatch中实现的。

1.遍历直到匹配或追加(method xfer)

从概念上讲，我们只是从头部开始遍历所有节点。如果我们遇到相反模式的不匹配节点，我们匹配它并返回，也将头部（至少2跳）更新为匹配节点之后的一个（或者如果它是固定的尾随节点则节点本身）。遍历还会检查是否有可能从列表中删除，在这种情况下它们会重新启动。
 如果到达列表的尾随节点，则无法进行匹配。如果这个调用是untimed poll或tryTransfer（参数“how”现在是），立即返回空。否则，新节点将附加CAS。成功追加时，如果此调用是ASYNC（例如offer），则元素已成功添加到队列末尾并返回。
 当然，当不可能匹配时，这种天真的遍历是O（n）。我们通过维护尾指针来优化遍历，尾指针预计会“接近”列表的末尾。如果它指向同一模式的节点，即使它已经死了（在这种情况下，通过此遍历仍然无法匹配前一节点），快速转发到尾部（在存在任意并发更改的情况下）是安全的。 ）。如果我们需要重新启动由于掉落列表，我们可以再次快进到尾部，但只有在自上次遍历后它已经改变（否则我们可能永远循环）。如果不能使用尾部，则从头部开始遍历（但在这种情况下，我们希望能够匹配近头）。与头部一样，我们CAS尾部指针至少推进两次。

2.等待匹配或取消（方法awaitMatch）

等待另一个线程匹配节点;而是取消当前线程是否被中断或等待超时。在多处理器上，我们使用队列前旋转：如果节点看起来是队列中第一个不匹配的节点，它会在阻塞之前旋转一点。在任何一种情况下，在阻塞之前它会尝试取消当前“head”和第一个不匹配节点之间的任何节点。
队列前旋转大大提高了大量争用队列的性能。只要它相对简短且“安静”，旋转对于较少争用的队列的性能影响不大。在旋转线程期间检查它们的中断状态并生成线程局部随机数，以决定偶尔执行Thread.yield。虽然产量规格不足，但我们认为限制纺纱对繁忙系统的影响可能会有所帮助，也不会受到影响。我们还使用较小的（1/2）旋转用于未知前端但其前身未被阻塞的节点 - 这些“链式”旋转避免了前端队列规则的伪像，否则会导致交替节点旋转与阻塞。此外，与其前任相比，表示相位变化（从数据到请求节点或反之亦然）的前线程接收额外的链式自旋，反映了在相位变化期间解锁线程通常所需的较长路径。

```
Unlinking removed interior nodes 
```

除了通过上述自我链接最小化垃圾保留之外，我们还取消了删除的内部节点的链接。这些可能是由于超时或中断等待或调用remove（x）或Iterator.remove而引起的。通常情况下，如果一个节点一度被称为要删除的某个节点的前身，我们可以通过CASing它的前任的下一个字段（如果它仍然指向s）来解除s（否则s必须已经存在）删除或现在是offlist）。但是有两种情况我们不能保证以这种方式使节点不可达：（1）如果s是列表的尾随节点（即，下一个是null），那么它被固定为追加的目标节点，所以只能在追加其他节点后删除。 （2）在给定匹配的前趋节点（包括被取消的情况）的情况下，我们不一定能够取消链接：前一个可能已经是未拼接的，在这种情况下，某些先前可达节点仍然可以指向s。 （有关进一步说明，请参阅Herlihy＆Shavit“多处理器编程的艺术”第9章）。虽然，在这两种情况下，如果s或其前任（或可以使其成为）或从列表负责人中脱离，我们可以排除采取进一步行动的必要性。
如果不考虑这些因素，有可能无限数量的所谓删除节点仍然可以访问。导致这种积累的情况并不常见，但在实践中可能会发生;例如，当一系列短暂的定时调用在尾随节点上重复超时但由于在队列前面对take（）进行了不定时调用而从不脱离列表。

当这些情况出现时，而不是总是回溯整个列表以找到一个实际的前导来取消链接（这对案例（1）无论如何都没有帮助），我们记录了对可能的非插入失败的保守估计（在“sweepVotes”中）。当估计超过阈值（“SWEEP_THRESHOLD”）时，我们触发全扫描，指示在扫描之前容许的估计移除失败的最大数量，取消链接在初始移除时未解除链接的取消节点。我们通过线程命中阈值（而不是后台线程或通过将工作分散到其他线程）来执行扫描，因为在发生删除的主要上下文中，调用者被超时或取消，这对时间要求不够严格以保证替代品会对其他线程施加的开销。
 因为sweepVotes估计是保守的，并且因为节点在从队列的头部落下时“自然地”取消链接，并且因为即使在扫描正在进行中我们允许投票累积，所以通常比估计的节点少得多。阈值的选择平衡了浪费努力和争用的可能性，而不是提供静态队列中内部节点保留的最坏情况限制。根据经验选择下面定义的值以在各种超时情况下平衡这些值。
 因为链接节点列表上的遍历操作是扫描死节点的自然机会，所以我们通常会这样做，包括可能在遍历时删除元素的所有操作，例如removeIf和Iterator.remove。除了取消或超时阻塞操作外，这在很大程度上消除了死链内部节点的长链。
 请注意，我们无法在扫描期间自行链接未链接的内部节点。但是，当一些后继者最终脱离列表的头部并且是自我链接时，相关的垃圾链终止。

### xfer()

```java
private E xfer(E e, boolean haveData, int how, long nanos) {
    if (haveData && (e == null))
        throw new NullPointerException();

    restart: for (Node s = null, t = null, h = null;;) {
        for (Node p = (t != (t = tail) && t.isData == haveData) ? t
                 : (h = head);; ) {
            final Node q; final Object item;
            if (p.isData != haveData //匹配
                && haveData == ((item = p.item) == null)) {
                if (h == null) h = head;
                if (p.tryMatch(item, e)) {
                    if (h != p) skipDeadNodesNearHead(h, p);
                    return (E) item;
                }
            }
            if ((q = p.next) == null) {
                if (how == NOW) return e;
                if (s == null) s = new Node(e);
                if (!p.casNext(null, s)) continue;
                if (p != t) casTail(t, s);
                if (how == ASYNC) return e;
                return awaitMatch(s, p, e, (how == TIMED), nanos);
            }
            if (p == (p = q)) continue restart;
        }
    }
}
```

xfer首先声明了几个变量，然后确定当前模式是插入还是删除。`(t != (t = tail) && t.isData == haveData)`先将尾指针赋值给t，然后判断此时t是否与赋值之前的t相等和isData字段是够为真。如果判断成功则将t赋值给节点p。失败将头节点赋值给p。

接下来判断p节点是否与当前进行的操作匹配（如果当前是take操作，则头结点有数据匹配。如果是offer,则尾部节点为null匹配），如果此时节点匹配。则调用`tryMatch`将p节点的`item`字段设置为`e`并唤醒等待线程。在调试过程中，p节点会将next字段指向自己，head节点会在匹配操作完成后向后移动一步，但是在匹配的代码当中并没有发现实现逻辑。offer方法也不会将线程阻塞。所以很奇怪这两一步是怎么执行的。

```java
final boolean tryMatch(Object cmp, Object val) {
    if (casItem(cmp, val)) {
        LockSupport.unpark(waiter);
        return true;
    }
    return false;
}
```

```java
final boolean casItem(Object cmp, Object val) {
    // assert isData == (cmp != null);
    // assert isData == (val == null);
    // assert !(cmp instanceof Node);
    return ITEM.compareAndSet(this, cmp, val);
}
```

替换成功后如果p不等于头结点，则调用skipDeadNodesNearHead删除已经匹配过的节点。

```java
private void skipDeadNodesNearHead(Node h, Node p) {
    // assert h != null;
    // assert h != p;
    // assert p.isMatched();
    for (;;) {
        final Node q;
        if ((q = p.next) == null) break;
        else if (!q.isMatched()) { p = q; break; } //如果p.next还没有匹配，则将q代替p。
        else if (p == (p = q)) return;//如果q节点已经到了尾巴，则直接返回
    }
    if (casHead(h, p))//将p设置为头结点
        h.selfLink();//将原头结点的next指向自己
}
```

如果操作不匹配，则进入第二if逻辑中。

```java
if ((q = p.next) == null) {
    if (how == NOW) return e;
    if (s == null) s = new Node(e);//新建节点
    if (!p.casNext(null, s)) continue;//将s设置为p的下一个节点
    if (p != t) casTail(t, s); //如果p不等于尾节点，则将s设置为尾节点
    if (how == ASYNC) return e; //如果是同步操作，则直接返回
    return awaitMatch(s, p, e, (how == TIMED), nanos); //等待
}
if (p == (p = q)) continue restart;
```

在`if (!p.casNext(null, s)) continue;`这一行中，假设最开始head=tail的时候，p也指向此时也指向tail，这一行执行过后按逻辑tail.next应该等于s。但通过调试发现p.next等于它自己，而head本应该等于p，但是现在等于s。也就是说链表此时是断开的。这种行为同上面一样不符合代码的逻辑，但是确实我没有找出其中的原因，所以。只能先到此为止，